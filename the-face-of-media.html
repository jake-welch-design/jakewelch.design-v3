<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>jakewelch.design | The Face of Media</title>
    <link rel="stylesheet" href="css/style.css" />
  </head>
  <body class="project-page">
    <div id="header-placeholder"></div>

    <main>
      <section class="project">
        <div class="project-header">
          <h1 class="project-title">THE FACE OF MEDIA</h1>
          <p class="project-year">(2023)</p>
        </div>
        <div class="project-content">
          <div class="project-image-single">
            <div class="iframe-wrapper">
              <iframe
                src="https://player.vimeo.com/video/898173536?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479"
                frameborder="0"
                allow="autoplay; fullscreen"
                allowfullscreen
              >
              </iframe>
            </div>
            <p class="project-image-caption">
              Screen capture of the program detecting facial expressions using playing a random clip based on the perceived emotion 
            </p>
          </div>

          <div class="project-details">
            <div class="project-type detail-section">
              <h2 class="detail-header">Project type</h2>
              <p class="detail-body">Interaction, installation, speculative</p>
            </div>
            <div class="project-tools detail-section">
              <h2 class="detail-header">Tools used</h2>
              <p class="detail-body">Python, machine learning, Processing</p>
            </div>
            <div class="project-description detail-section">
              <h2 class="detail-header">Project description</h2>
              <p class="detail-body">
                The Face of Media is a speculative installation designed to explore machine learning as a UI tool to surpass language barriers. 
              </p>
            </div>
            <div class="project-links detail-section">
              <h2 class="detail-header">Links</h2>
              <p class="detail-body">
                <a href="https://github.com/phamquiluan/ResidualMaskingNetwork/tree/master">â†³ "Residual masking network" code by Luan Pham used in the project</a>
              </p>
            </div>
          </div>
        </div>

        <div class="project-text">
          <p>
            Developed during the spring 2023 Multi-Disciplinary Design junior studio in the College of Architecture & Planning at the University of Utah, this project is a speculative installation designed to explore machine learning as a UI tool to overcome language barriers. Attendees approaching the exhibit would have their face analayzed & a machine learning algorithm would determine whether their face was expressing one of seven emotions: neutral, happy, sad, anger, disgust, surprise, or fear. Based on the perceived emotion, the program would automatically play a random video clip exhibiting said emotion. 
          </p>
        </div>
        
        <div class="project-image-double">
          <div>
            <img src="images/tfom.jpg" alt="Setup of the final exhibit" />
            <p class="project-image-caption">Setup of the final exhibit</p>
          </div>
          <div>
            <img src="images/tfom-02.jpg" alt="Attendee interacting with the exhibit with a 'surprised' expression" />
            <p class="project-image-caption">
              Attendee interacting with the exhibit with a 'surprised' expression
            </p>
          </div>
        </div>

        <div class="project-text">
          <p>
            The exhibit consisted of a camera, a screen, an optional button for halting video playback, & instructions. It worked by running a facial emotion recognition (FER) algorithm consisting of a residual masking network framework & tensorflow in Python, & sending the perceived emotion to a  program written in Processing via websocket that could then handle video playback. The Processing program would use this data to pick from "emotion" categories to play a random video related to the expression. Once a video would start playing, attendees could then have the option to press a green button to halt playback if desired. 
          </p>
        </div>
        </div>
      </section>
    </main>
    <div id="footer-placeholder"></div>

    <script src="javascript/scramble.js"></script>
    <script src="javascript/dropdown-menu.js"></script>
    <!--     <script src="javascript/cursor.js"></script> -->
    <script src="javascript/load-components.js"></script>
  </body>
</html>
